{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every single classification has its own biases and does not enjou superiory over thers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sympy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Thus, Rosenblatt's initial perceptron rule is fairly simple and can be summarized by the following steps:\n",
    "1. Initialize the weights to 0 or small random numbers.\n",
    "2. For each training sample x(i) perform the following steps:\n",
    " 1. Compute the output value yˆ .\n",
    " 2. Update the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "X = np.random.randn(4,5)\n",
    "y = [1,1,-1,1]\n",
    "eta=0.01\n",
    "n_iter=10\n",
    "w = np.zeros(1 + X.shape[1])\n",
    "errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00586062,  0.0013624 ,  0.01887613,  0.02322079, -0.03492402])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = np.dot(X, w[1:]) + w[0]\n",
    "errors = out-y\n",
    "eta * np.dot(X.T, errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.84901851e-01  -4.58404648e-01   1.54986851e-04  -5.27570534e-01\n",
      "   1.22673047e-01]\n",
      "1\n",
      "[ 0.62169884 -0.36192734 -0.21895215 -1.64008967 -0.69497986]\n",
      "1\n",
      "[ 0.60717296 -0.36905758  0.97832874 -1.15407406  0.16456298]\n",
      "-1\n",
      "[-0.29156577 -0.00612563 -1.81164727 -0.53339836  0.99452069]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for xi, target in zip(X, y):\n",
    "    print(xi)\n",
    "    print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Adaline\n",
    "\n",
    "In the adaline function instead of unit step function we use a linear function. The advantage of using linear function is that it is a convex function and can be minimized to a local minima. \n",
    "\n",
    "- The concept of gradient descent is that a local minima can be achieved until a global cost function\n",
    "\n",
    "- We take a step away from the gradient in each interation and the step size is determined by the value of learning rate as well as the slope of gradient\n",
    "\n",
    "\n",
    "As this is run on the entire training data it is called as batch tarining algorithm. When the data is in millions this becomes computationally inefficient and henc ewe use stichastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent\n",
    "\n",
    "In this instead of updating teh weights based on the accumulated errors of all samples we update the weight incrementally for each sample. \n",
    "\n",
    "- Although stochastic gradient descent can be considered as an approximation of gradient descent, it typically reaches convergence much faster because of the more frequent weight updates\n",
    "\n",
    "- stochastic gradient descent can escape shallow local minima more readily. To obtain accurate results via stochastic gradient descent, it is important to present it with data in a random order\n",
    "\n",
    "> In stochastic gradient descent implementations, the fixed learning rate η is often replaced by an adaptive learning rate that decreases over time\n",
    "\n",
    "- stochastic gradient descent does not reach the global minimum but an area very close to it. By using an adaptive learning rate, we can achieve further annealing to a better global minimum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"No Free Lunch\" theorem: no single classifier works best across all possible scenarios. In practice, it is always recommended that you compare the performance of at least a handful of different learning algorithms to select the best model for the particular problem; these may differ in the number of features\n",
    "or samples, the amount of noise in a dataset, and whether the classes are linearly separable or not."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
